<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <link rel="stylesheet" type="text/css" href="/assets/css/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <title>My GitHub Repository by </title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1><a href="index">My GitHub Repository</a></h1>
          <h2>Where computing, maths, and business hang out</h2>
        </header>

        <section id="main_content">
          <h2 id="cutting-through-kaggle-jargon">Cutting through Kaggle Jargon</h2>

<p>The <a href="https://www.kaggle.com/discussion">Kaggle discussion forums</a> are often a place of data science knowledge gained from experience. Rather than letting such knowledge gather dust on the discussion boards I thought Iâ€™d capture them into one handy page.</p>

<h3 id="steps-for-tackling-a-kaggle-competition">Steps for tackling a Kaggle competition</h3>
<ul>
  <li>
    <p>Explore the data, which includes basic outlier analysis.</p>
  </li>
  <li>
    <p>Force myself to write error analysis code before I start building a model. (This is hard to stay true to, but worth the effort.). For example, if the contest is binary prediction, I might graph a histogram of predicted probabilities for the positive an negative classes and plot a calibration curve. (Of course, you need to do out-of-fold predictions against your training data to do this.) You could also plot your log-loss versus each categorical variable or binned continuous variable, etc.</p>
  </li>
</ul>

<p>If you find that a certain feature value is an outlier compared to the rest of the data set, you could then, e.g., consider whether you might want to separate them out an train two different models. Or perhaps there is some feature engineering or transformation that might help.</p>

<h3 id="some-notable-reads">Some notable reads</h3>
<p>http://blog.kaggle.com/2016/11/17/painter-by-numbers-competition-1st-place-winners-interview-nejc-ilenic/</p>

        </section>

        <footer>
        
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.
        </footer>

      </div>
    </div>

    
  </body>
</html>
