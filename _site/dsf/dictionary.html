<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <link href='https://fonts.googleapis.com/css?family=Chivo:900' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <link rel="stylesheet" type="text/css" href="/assets/css/print.css" media="print">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <title>Badrul's Data Science Repository by </title>
  </head>

  <body>
    <div id="container">
      <div class="inner">

        <header>
          <h1><a href="index">Badrul's Data Science Repository</a></h1>
          <h2>Computing, Maths, Business, Bioinformatics</h2>
        </header>

        <section id="main_content">
		<h2 id="a-concise-dictionary-of-data-science-terminology">A concise dictionary of data-science terminology</h2>

		<ul>
			
  			<li>
    			<a href="">
      			Batch size<br>
    			</a>
			
				the number of training examples in one forward / backward pass. The higher the batch size the the more memory you will need.<br><br>
			

			
			
			

  			</li><br>
			
  			<li>
    			<a href="http://cs231n.github.io/convolutional-networks/">
      			Convolutional Neural Networks<br>
    			</a>
			
				ANN architecture specifically for images in which the hidden layers are partioned into different sections known as filters.  See http://cs231n.github.io/convolutional networks/  and https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/<br><br>
			

			
			
			

  			</li><br>
			
  			<li>
    			<a href="">
      			Decision boundary<br>
    			</a>
			
				the boundary between decision regions<br><br>
			

			
			
			
      				<i>Related to: Decision boundary</i><br>
			

  			</li><br>
			
  			<li>
    			<a href="">
      			Decision region<br>
    			</a>
			
				a subset of your solution space that has been labelled as one classification.<br><br>
			

			
			
			
      				<i>Related to: Decision boundary</i><br>
			

  			</li><br>
			
  			<li>
    			<a href="">
      			Embedding layer<br>
    			</a>
			
				The representation of ANN input into a dense vector of fixed size. eg. [0.25, 0.1], [0.6, -0.2], and thereby becomes first layer of a model (in other words you end up training on embedding layer > output  not input > output<br><br>
			

			
			
			

  			</li><br>
			
  			<li>
    			<a href="">
      			Epoch<br>
    			</a>
			
				In ANN's, One forward pass and one backward pass of ALL the training examples.<br><br>
			

			
			
			

  			</li><br>
			
  			<li>
    			<a href="http://machinelearningmastery.com/gradient-descent-for-machine-learning/">
      			Gradient descent<br>
    			</a>
			
				A class of algorithms for narrowing down on the optimal solution in a search space where the optimal value cannot be derived mathematically<br><br>
			

			
			
			

  			</li><br>
			
  			<li>
    			<a href="https://en.wikipedia.org/wiki/Logistic_regression">
      			Logistic Regression<br>
    			</a>
			
				A regresion model in which the predicted value is categorical<br><br>
			

			
			
			
      				<i>Related to: Multinomial logistic regression</i><br>
			

  			</li><br>
			
  			<li>
    			<a href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">
      			Multinomial logistic regression<br>
    			</a>
			
				A regresion model in which the predicted value is categorical and has more than two possible outcomes<br><br>
			

			
      				<i>Also known as: polytomous LR,multiclass LR, softmax regression, multinomial logit, maximum entropy (MaxEnt) classifier, conditional maximum entropy model</i><br>
			
			
			
      				<i>Related to: logistic Regression</i><br>
			

  			</li><br>
			
  			<li>
    			<a href="https://www.quora.com/What-is-one-hot-encoding-and-when-is-it-used-in-data-science">
      			One hot encoding<br>
    			</a>
			
				A vector is a vector which is 0 in most dimensions, and 1 in a single dimension<br><br>
			

			
			
			

  			</li><br>
			
  			<li>
    			<a href="">
      			Recurrent Neural Network<br>
    			</a>
			
				Contrary to feedforward networks, recurrent neural networks (RNNs) are models with bi-directional data flow. While a feedforward network propagates data linearly from input to output, RNNs also propagate data from later processing stages to earlier stages.<br><br>
			

			
			
			

  			</li><br>
			
  			<li>
    			<a href="https://en.wikipedia.org/wiki/Sparse_matrix#Storing_a_sparse_matrix">
      			Sparse matrix<br>
    			</a>
			
				A sparse matrix is a matrix in which most of the elements are zero, such as in ine-hot encoding. When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix. Different data structures can be used and yield huge savings in memory when compared to the basic approach. The trade-off is that accessing the individual elements becomes more complex and additional structures are needed to be able to recover the original matrix unambiguously.<br><br>
			

			
			
			

  			</li><br>
			
  			<li>
    			<a href="">
      			<template><br>
    			</a>
			
				<description><br><br>
			

			
			
			

  			</li><br>
			
		</ul>
		
        </section>

        <footer>
        
          This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.
        </footer>

      </div>
    </div>

    
  </body>
</html>
